{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_path  = \"./classify-birds/\" \n",
    "train_path = program_path + \"train_set\"\n",
    "# val_path = program_path + \"val_set\"\n",
    "test_path = program_path + \"test_set\"\n",
    "classes_path = program_path + \"classes.txt\"\n",
    "pred_path = './'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.Black_footed_Albatross_112.jpg', '001.Black_footed_Albatross_1131.jpg'] 10010\n",
      "['1.jpg', '10.jpg'] 1768\n"
     ]
    }
   ],
   "source": [
    "def get_image_list(path):\n",
    "    lst = []\n",
    "    for img in sorted(os.listdir(path)):\n",
    "        if img != '.ipynb_checkpoints':\n",
    "            lst.append(img)            # 1.jpg\n",
    "    return lst\n",
    "\n",
    "\n",
    "train_list = get_image_list(train_path)\n",
    "test_list = get_image_list(test_path)\n",
    "\n",
    "print(train_list[:2], len(train_list))\n",
    "print(test_list[:2], len(test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold(image_list, k):\n",
    "    indexs = [int(img.split('.')[0]) - 1 for img in image_list]\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    train_kfold = []\n",
    "    valid_kfold = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(image_list, indexs)):\n",
    "        train_kfold.append([image_list[i] for i in train_idx])\n",
    "        valid_kfold.append([image_list[j] for j in val_idx])\n",
    "    return train_kfold, valid_kfold\n",
    "\n",
    "tk, vk = get_kfold(train_list, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_data(train_list):\n",
    "    dct = {}\n",
    "    for img in train_list:\n",
    "        label = (img.split('.')[0])\n",
    "        if label not in dct:\n",
    "            dct[label] = 1\n",
    "        else:\n",
    "            dct[label] += 1\n",
    "    print(dct)\n",
    "# 平均每个类别有50张左右的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_dict(classes_path):\n",
    "    match_dict = {}\n",
    "    with open(classes_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            no = int(line.split(\" \")[0])\n",
    "            name = line.split(\" \")[1].split(\".\")[1]\n",
    "            match_dict[no] = name\n",
    "    return match_dict\n",
    "\n",
    "match_dict = get_match_dict(classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataSet(Dataset):\n",
    "    def __init__(self, image_list, image_folder, transform=None):\n",
    "        super().__init__()\n",
    "        self.image_list = image_list           # 图像名称的列表\n",
    "        self.image_foder = image_folder        # 图像所在文件夹\n",
    "        self.transform = transform             \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_foder, self.image_list[idx])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = int(self.image_list[idx].split('.')[0]) - 1\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels//ratio, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels//ratio, in_channels, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1  #通道升降维倍数\n",
    "    def __init__(self, in_channels, channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, \n",
    "                                stride=stride, padding=1)                    #第一个卷积层，通过stride进行下采样\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3,            #第二个卷积层，不进行下采样\n",
    "                                stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.ca = ChannelAttention(channels)                                 #加入卷积注意力模块\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)                                       #通道数不变，1x1卷积层仅用于降采样\n",
    "\n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4  # 通道升降维背书\n",
    "\n",
    "    def __init__(self, in_channels, channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, channels,                     #第一个是1x1卷积\n",
    "                                kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)                                 \n",
    "\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3,        #第二个是3x3卷积，通过stride进行下采样\n",
    "                                stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(channels, channels * self.expansion,      #第三个是1x1卷积\n",
    "                                kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * channels)\n",
    "\n",
    "        self.ca = ChannelAttention(channels * self.expansion)           #加入卷积注意力模块\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)                                       #通道数变化，需要在shortcut中加入1x1卷积升维，同时降采样\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.in_channels = 64\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])                #第一个残差层不进行下采样\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.embedding = nn.Linear(num_classes, 512)\n",
    "        self.classify = nn.Linear(512, 200)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, channels, blocks, stride=1):                          # block：basicblock or bottleneck\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != channels * block.expansion:              # 前一种操作需要下采样，后一种操作需要融合通道\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, channels*block.expansion, kernel_size=1, \n",
    "                        stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channels*block.expansion)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))         #第一个残差块\n",
    "        self.in_channels = channels * block.expansion                                \n",
    "        for i in range(1, blocks):                                                   #后续残差块，需要改变in_channels，使其对应上一个残差块的channels\n",
    "            layers.append(block(self.in_channels, channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.embedding(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "def resnet34_cbam(pretrained=False, **kwargs):\n",
    "    \n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch, batch_size, lr = 13, 48, 0.0005\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(0.4, 0.2, 0.4, 0.2),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "models = [resnet34_cbam(True) for i in range(5)]\n",
    "for model in models:\n",
    "    model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [{\"params\": mlp.parameters()} for mlp in models],\n",
    "    lr=lr\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, val_set, val_iter, epoch):\n",
    "    model.eval()\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    for step, (X, y) in enumerate(val_iter):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)      \n",
    "        \n",
    "        y_hat = model(X)\n",
    "        loss = criterion(y_hat, y)\n",
    "        pred = torch.argmax(y_hat, dim=1)\n",
    "                \n",
    "        accuracy = torch.sum(pred == y).item()\n",
    "        val_acc += accuracy\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        \n",
    "    val_acc /= len(val_set)\n",
    "    val_loss /= (step + 1)\n",
    "    if epoch % 3 == 0:\n",
    "        print(f\"------valid| acc={val_acc:.6f}, loss={val_loss:.6f}-----\")\n",
    "\n",
    "    return val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(models):\n",
    "    \n",
    "    for k in range(5):\n",
    "        acc = 0.0\n",
    "        train_set = BirdDataSet(tk[k], train_path, transform=train_transform)\n",
    "        train_iter = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "        val_set = BirdDataSet(vk[k], train_path, transform=val_transform)\n",
    "        val_iter = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "        \n",
    "        for epoch in range(num_epoch):\n",
    "            models[k].train()\n",
    "            epoch_acc = 0\n",
    "            epoch_loss = 0\n",
    "            for step, (X, y) in enumerate(train_iter):\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "            \n",
    "                y_hat = models[k](X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                pred = torch.argmax(y_hat, dim=1)\n",
    "                accuracy = torch.sum(pred == y).item()\n",
    "                epoch_acc += accuracy\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "              \n",
    "            epoch_acc /= len(train_set)\n",
    "            epoch_loss /= (step + 1)\n",
    "            if epoch % 3 == 0:\n",
    "                print(f\"|model{k} epoch{epoch:>2d}| acc={epoch_acc:.6f}, loss={epoch_loss:.6f}\")\n",
    "            \n",
    "            scheduler.step()\n",
    "            val_acc = valid(models[k], val_set, val_iter, epoch)\n",
    "            \n",
    "        \n",
    "            if val_acc > acc:\n",
    "                torch.save(models[k].state_dict(), f'./model{k}.pth')\n",
    "                acc = val_acc\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|model0 epoch 0| acc=0.032592, loss=4.806515\n",
      "------valid| acc=0.068432, loss=4.194335-----\n",
      "|model0 epoch 3| acc=0.388487, loss=2.196995\n",
      "------valid| acc=0.347153, loss=2.545099-----\n",
      "|model0 epoch 6| acc=0.665584, loss=1.106947\n",
      "------valid| acc=0.491009, loss=1.972775-----\n",
      "|model0 epoch 9| acc=0.810190, loss=0.596662\n",
      "------valid| acc=0.554446, loss=1.832113-----\n",
      "|model0 epoch12| acc=0.912338, loss=0.270933\n",
      "------valid| acc=0.533467, loss=2.267678-----\n",
      "|model1 epoch 0| acc=0.056319, loss=4.533703\n",
      "------valid| acc=0.109391, loss=4.135606-----\n",
      "|model1 epoch 3| acc=0.522478, loss=1.622074\n",
      "------valid| acc=0.449051, loss=1.975354-----\n",
      "|model1 epoch 6| acc=0.769730, loss=0.754174\n",
      "------valid| acc=0.450549, loss=2.233846-----\n",
      "|model1 epoch 9| acc=0.884241, loss=0.365400\n",
      "------valid| acc=0.595904, loss=1.801501-----\n",
      "|model1 epoch12| acc=0.947552, loss=0.171486\n",
      "------valid| acc=0.593407, loss=1.970936-----\n",
      "|model2 epoch 0| acc=0.054695, loss=4.538333\n",
      "------valid| acc=0.129371, loss=3.654449-----\n",
      "|model2 epoch 3| acc=0.568681, loss=1.442554\n",
      "------valid| acc=0.499500, loss=1.798679-----\n",
      "|model2 epoch 6| acc=0.822303, loss=0.583722\n",
      "------valid| acc=0.598402, loss=1.513494-----\n",
      "|model2 epoch 9| acc=0.912962, loss=0.277102\n",
      "------valid| acc=0.583417, loss=1.818398-----\n",
      "|model2 epoch12| acc=0.952298, loss=0.155530\n",
      "------valid| acc=0.619381, loss=1.844676-----\n",
      "|model3 epoch 0| acc=0.045954, loss=4.701678\n",
      "------valid| acc=0.124376, loss=3.751396-----\n",
      "|model3 epoch 3| acc=0.625000, loss=1.270734\n",
      "------valid| acc=0.548452, loss=1.573065-----\n",
      "|model3 epoch 6| acc=0.870754, loss=0.450624\n",
      "------valid| acc=0.655345, loss=1.331582-----\n",
      "|model3 epoch 9| acc=0.960165, loss=0.149152\n",
      "------valid| acc=0.649850, loss=1.469967-----\n",
      "|model3 epoch12| acc=0.981269, loss=0.073942\n",
      "------valid| acc=0.679321, loss=1.393629-----\n",
      "|model4 epoch 0| acc=0.031843, loss=4.930377\n",
      "------valid| acc=0.074925, loss=4.176375-----\n",
      "|model4 epoch 3| acc=0.553821, loss=1.564161\n",
      "------valid| acc=0.527473, loss=1.676033-----\n",
      "|model4 epoch 6| acc=0.842408, loss=0.545142\n",
      "------valid| acc=0.618382, loss=1.407453-----\n",
      "|model4 epoch 9| acc=0.949925, loss=0.202621\n",
      "------valid| acc=0.633866, loss=1.532074-----\n",
      "|model4 epoch12| acc=0.980894, loss=0.084983\n",
      "------valid| acc=0.654845, loss=1.528206-----\n"
     ]
    }
   ],
   "source": [
    "train(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def predict(models, test_list, image_folder, pred_path, mode='gpu'):\n",
    "    if mode == 'gpu':\n",
    "        for model in models:\n",
    "            model.to(torch.device('cuda'))\n",
    "    \n",
    "    with open(pred_path + \"pred.csv\", \"w\") as f:\n",
    "        for i in range(len(test_list)):\n",
    "            name = str(i + 1) + \".jpg\"\n",
    "            ipath = os.path.join(image_folder, name)\n",
    "            img = Image.open(ipath).convert('RGB')\n",
    "            img = val_transform(img)\n",
    "            img = img.unsqueeze(dim=0)\n",
    "            if mode == 'gpu':\n",
    "                img = img.to(torch.device('cuda'))\n",
    "            vote = []\n",
    "            for mlp in models:\n",
    "                pred = mlp(img).argmax(dim=1)\n",
    "                vote.append(pred.cpu().numpy())\n",
    "            vote = np.array(vote)\n",
    "            label = Counter(vote[:, 0]).most_common(1)[0][0] + 1\n",
    "            f.write(\"{},{}\\n\".format(name, label))\n",
    "            if i % 100 == 0 : \n",
    "                print(name, match_dict[label])\n",
    "\n",
    "            \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg Painted_Bunting\n",
      "101.jpg European_Goldfinch\n",
      "201.jpg House_Wren\n",
      "301.jpg Northern_Fulmar\n",
      "401.jpg Chipping_Sparrow\n",
      "501.jpg Frigatebird\n",
      "601.jpg Forsters_Tern\n",
      "701.jpg Winter_Wren\n",
      "801.jpg Green_Kingfisher\n",
      "901.jpg Sage_Thrasher\n",
      "1001.jpg Chuck_will_Widow\n",
      "1101.jpg Western_Meadowlark\n",
      "1201.jpg Pacific_Loon\n",
      "1301.jpg Cliff_Swallow\n",
      "1401.jpg Pine_Grosbeak\n"
     ]
    }
   ],
   "source": [
    "predict(models, test_list, test_path, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "clones = [resnet34_cbam() for i in range(5)]\n",
    "for i, clone in enumerate(clones):\n",
    "    clone.to(torch.device('cuda'))\n",
    "    clone.load_state_dict(torch.load(f\"model{i}.pth\"))\n",
    "    clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clones, test_list, test_path, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = resnet34_cbam(False)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('model4.pth'))\n",
    "model.eval()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1be9754ee79610231792a5d41e568e73717e3449dc6354b7dd630d948f54848a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
